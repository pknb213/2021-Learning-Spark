{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from timeit import default_timer as timer\n",
    "import pyspark\n",
    "\n",
    "# Changed to \"Program Files (x86) >> Progra~2\"\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Progra~2\\Java\\jre1.8.0_201\"\n",
    "pd_df = pd.read_csv(\"./listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                               name    host_id  \\\n",
      "0        197677                          Oshiage Holiday Apartment     964081   \n",
      "1        776070                             Kero-kero house room 1     801494   \n",
      "2        899003                  Classy room @Shinjuku, Takadanoba    4799233   \n",
      "3       1016831     WOMAN ONLY LICENSED ! Cosy & Cat behnd Shibuya    5596383   \n",
      "4       1033276                           private room @Senju area    5686404   \n",
      "...         ...                                                ...        ...   \n",
      "11303  48245895                                有民宿许可、新宿駅徒歩圏、有付费停车位   49474412   \n",
      "11304  48248681                         【宿家】千束町 浅草 酉の市 鷲神社の裏にある一軒家  176875986   \n",
      "11305  48248916              新宿Shinjuku-ku 4bedroom豪华公寓， 新大久保駅徒歩２分   43826309   \n",
      "11306  48258253  Near to Sensoji  Temple.Japanese traditional h...   34415001   \n",
      "11307  48260803      STUDIO APARTMENT in GREAT LOCATION / SHINJUKU  165921683   \n",
      "\n",
      "             host_name  neighbourhood_group neighbourhood  latitude  \\\n",
      "0      Yoshimi & Marek                  NaN     Sumida Ku  35.71721   \n",
      "1                  Kei                  NaN       Kita Ku  35.73844   \n",
      "2                   Yu                  NaN   Shinjuku Ku  35.70865   \n",
      "3               Wakana                  NaN   Setagaya Ku  35.65833   \n",
      "4               Yukiko                  NaN     Adachi Ku  35.74253   \n",
      "...                ...                  ...           ...       ...   \n",
      "11303             Dong                  NaN   Shinjuku Ku  35.69420   \n",
      "11304           Yadoya                  NaN      Taito Ku  35.72089   \n",
      "11305             Momo                  NaN   Shinjuku Ku  35.70376   \n",
      "11306            Cheng                  NaN      Taito Ku  35.71585   \n",
      "11307            Tokyo                  NaN   Shinjuku Ku  35.69769   \n",
      "\n",
      "       longitude        room_type  price  minimum_nights  number_of_reviews  \\\n",
      "0      139.82596  Entire home/apt  11000               3                165   \n",
      "1      139.76917     Private room   7428               3                228   \n",
      "2      139.69681  Entire home/apt   5200              30                 93   \n",
      "3      139.67153     Private room  11000               1                211   \n",
      "4      139.79730     Private room  30000               1                 72   \n",
      "...          ...              ...    ...             ...                ...   \n",
      "11303  139.69182  Entire home/apt   5000               2                  0   \n",
      "11304  139.79126  Entire home/apt  10309               1                  0   \n",
      "11305  139.70007  Entire home/apt  28000               1                  0   \n",
      "11306  139.79975  Entire home/apt  20000               3                  0   \n",
      "11307  139.70470  Entire home/apt   2271               1                  0   \n",
      "\n",
      "      last_review  reviews_per_month  calculated_host_listings_count  \\\n",
      "0      2020-03-04               1.44                               1   \n",
      "1      2020-01-18               2.27                               1   \n",
      "2      2019-11-25               0.95                               2   \n",
      "3      2020-03-16               2.19                               1   \n",
      "4      2018-06-17               0.76                               2   \n",
      "...           ...                ...                             ...   \n",
      "11303         NaN                NaN                               8   \n",
      "11304         NaN                NaN                              35   \n",
      "11305         NaN                NaN                              22   \n",
      "11306         NaN                NaN                               5   \n",
      "11307         NaN                NaN                               8   \n",
      "\n",
      "       availability_365  \n",
      "0                   328  \n",
      "1                   146  \n",
      "2                     0  \n",
      "3                   139  \n",
      "4                   271  \n",
      "...                 ...  \n",
      "11303               292  \n",
      "11304                 0  \n",
      "11305               178  \n",
      "11306               132  \n",
      "11307                 0  \n",
      "\n",
      "[11308 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "field last_review: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-8b611afa2203>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mpyspark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msql\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStructField\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"last_review\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msql\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStringType\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m ])\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0msp_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreateDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\session.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[1;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[0;32m    672\u001B[0m             \u001B[1;31m# Create a DataFrame from pandas DataFrame.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    673\u001B[0m             return super(SparkSession, self).createDataFrame(\n\u001B[1;32m--> 674\u001B[1;33m                 data, schema, samplingRatio, verifySchema)\n\u001B[0m\u001B[0;32m    675\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    676\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[1;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[0;32m    298\u001B[0m                     \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    299\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_convert_from_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 300\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    301\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    302\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_convert_from_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\session.py\u001B[0m in \u001B[0;36m_create_dataframe\u001B[1;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[0;32m    698\u001B[0m             \u001B[0mrdd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_createFromRDD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    699\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 700\u001B[1;33m             \u001B[0mrdd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_createFromLocal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    701\u001B[0m         \u001B[0mjrdd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jvm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerDeUtil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoJavaArray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrdd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_to_java_object_rdd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    702\u001B[0m         \u001B[0mjdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapplySchemaToPythonRDD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjrdd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrdd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\session.py\u001B[0m in \u001B[0;36m_createFromLocal\u001B[1;34m(self, data, schema)\u001B[0m\n\u001B[0;32m    510\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    511\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mschema\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 512\u001B[1;33m             \u001B[0mstruct\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inferSchemaFromList\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mschema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    513\u001B[0m             \u001B[0mconverter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_create_converter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstruct\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    514\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconverter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\session.py\u001B[0m in \u001B[0;36m_inferSchemaFromList\u001B[1;34m(self, data, names)\u001B[0m\n\u001B[0;32m    437\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"can not infer schema from empty dataset\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 439\u001B[1;33m         \u001B[0mschema\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_merge_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0m_infer_schema\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    440\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_has_nulltype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    441\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Some of types cannot be determined after inferring\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\types.py\u001B[0m in \u001B[0;36m_merge_type\u001B[1;34m(a, b, name)\u001B[0m\n\u001B[0;32m   1107\u001B[0m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001B[0;32m   1108\u001B[0m                                                   name=new_name(f.name)))\n\u001B[1;32m-> 1109\u001B[1;33m                   for f in a.fields]\n\u001B[0m\u001B[0;32m   1110\u001B[0m         \u001B[0mnames\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfields\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1111\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnfs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\types.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1107\u001B[0m         fields = [StructField(f.name, _merge_type(f.dataType, nfs.get(f.name, NullType()),\n\u001B[0;32m   1108\u001B[0m                                                   name=new_name(f.name)))\n\u001B[1;32m-> 1109\u001B[1;33m                   for f in a.fields]\n\u001B[0m\u001B[0;32m   1110\u001B[0m         \u001B[0mnames\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfields\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1111\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnfs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cheon\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\types.py\u001B[0m in \u001B[0;36m_merge_type\u001B[1;34m(a, b, name)\u001B[0m\n\u001B[0;32m   1100\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1101\u001B[0m         \u001B[1;31m# TODO: type cast (such as int -> long)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1102\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_msg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Can not merge type %s and %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m     \u001B[1;31m# same type\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: field last_review: Can not merge type <class 'pyspark.sql.types.StringType'> and <class 'pyspark.sql.types.DoubleType'>"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate(pyspark.SparkConf().setMaster(\"local[*]\"))\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "schema = pyspark.sql.types.StructType([\n",
    "    pyspark.sql.types.StructField(\"id\", pyspark.sql.types.StringType(), True),\n",
    "    pyspark.sql.types.StructField(\"last_review\", pyspark.sql.types.StringType(), True)\n",
    "])\n",
    "sp_df = spark.createDataFrame(pd_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sp_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}